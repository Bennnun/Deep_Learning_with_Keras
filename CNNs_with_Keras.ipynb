{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs_with_Keras",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Deep_Learning_with_Keras/blob/master/CNNs_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Zsa1vXyWlNvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n",
        "\n",
        "<h1 align=center><font size = 5>Convolutional Neural Networks with Keras</font></h1>"
      ]
    },
    {
      "metadata": {
        "id": "WUFMiyRglNvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this lab, we will learn how to use the keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
      ]
    },
    {
      "metadata": {
        "id": "iRknh_felNvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "      \n",
        "1. <a href=\"#item2\">Import Keras and Packages</a>   \n",
        "2. <a href=\"#item3\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
        "3. <a href=\"#item4\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
        "\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "Lq2rZRLClNvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Keras and Packages"
      ]
    },
    {
      "metadata": {
        "id": "qA95Af-2lNvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's start by importing the keras libraries and the packages that we would need to build a neural network."
      ]
    },
    {
      "metadata": {
        "id": "9yDpjSUs_2Vu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import Pandas \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGvLOcsPlNvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import Keras \n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bupp0MWQlNvT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When working with convolutional neural networks in particular, we will need additional packages."
      ]
    },
    {
      "metadata": {
        "id": "bFO463j0lNvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import additional Keras packages\n",
        "from keras.layers import Flatten                     ### To flatten data for fully connected layers\n",
        "from keras.layers.convolutional import Conv2D        ### To add convolutional layers\n",
        "from keras.layers.convolutional import MaxPooling2D  ### To add pooling layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHHW5NnclNvT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layer with two sets of convolutional and pooling layers"
      ]
    },
    {
      "metadata": {
        "id": "QYbsix7GlNvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12240
        },
        "outputId": "d441a428-3a93-439e-8291-c67780ca675c"
      },
      "cell_type": "code",
      "source": [
        "### Import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "### Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "### Print 'X_train' and 'X_test' \n",
        "print(\"X_train:\\n\",  X_train, '\\n')\n",
        "print(\"X_test:\\n\", X_test, '\\n')\n",
        "\n",
        "### Reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "### Print reshaped 'X_train' and 'X_test'\n",
        "print(\"Reshaped X_train:\\n\", X_train, '\\n')\n",
        "print(\"Resahped X_test:\\n\", X_test) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:\n",
            " [[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]] \n",
            "\n",
            "X_test:\n",
            " [[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]] \n",
            "\n",
            "Reshaped X_train:\n",
            " [[[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]] \n",
            "\n",
            "Resahped X_test:\n",
            " [[[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KZYSzZqylNvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's normalize the pixel values to be between 0 and 1"
      ]
    },
    {
      "metadata": {
        "id": "E671oE3JlNvi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLPDkR6JlNvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, let's convert the target variable into binary categories"
      ]
    },
    {
      "metadata": {
        "id": "fAH9v19hlNvi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cepGXuAelNvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers."
      ]
    },
    {
      "metadata": {
        "id": "MtbsbmvxlNvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9BHCqSTlNvy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, let's call the function to create the model, and then let's train it and evaluate it."
      ]
    },
    {
      "metadata": {
        "id": "2ZzEDLKglNvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7650b668-5061-4b0a-b7c4-4218bd471b3f"
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 6s - loss: 0.2889 - acc: 0.9190 - val_loss: 0.1010 - val_acc: 0.9710\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.0860 - acc: 0.9752 - val_loss: 0.0639 - val_acc: 0.9802\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0577 - acc: 0.9829 - val_loss: 0.0630 - val_acc: 0.9795\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0448 - acc: 0.9866 - val_loss: 0.0398 - val_acc: 0.9861\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0360 - acc: 0.9891 - val_loss: 0.0372 - val_acc: 0.9876\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0300 - acc: 0.9909 - val_loss: 0.0350 - val_acc: 0.9874\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0340 - val_acc: 0.9887\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0359 - val_acc: 0.9877\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0420 - val_acc: 0.9872\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0351 - val_acc: 0.9877\n",
            "Accuracy: 0.9877 \n",
            " Error: 1.230000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rVAai4uclNwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "------------------------------------------"
      ]
    },
    {
      "metadata": {
        "id": "oP7TEkzHlNwE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layer with two sets of convolutional and pooling layers"
      ]
    },
    {
      "metadata": {
        "id": "-69h_SFYlNwG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each."
      ]
    },
    {
      "metadata": {
        "id": "HFN5-EdTlNwH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWPZLhYTlNwK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it."
      ]
    },
    {
      "metadata": {
        "id": "4BVoKhSTlNwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "0633df35-5c94-4821-fda1-3b89f56e1cee"
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 0.4869 - acc: 0.8538 - val_loss: 0.1513 - val_acc: 0.9559\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1230 - acc: 0.9639 - val_loss: 0.0813 - val_acc: 0.9744\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0844 - acc: 0.9741 - val_loss: 0.0679 - val_acc: 0.9788\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0676 - acc: 0.9794 - val_loss: 0.0631 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0572 - acc: 0.9825 - val_loss: 0.0468 - val_acc: 0.9860\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0494 - acc: 0.9851 - val_loss: 0.0468 - val_acc: 0.9844\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0447 - acc: 0.9866 - val_loss: 0.0455 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0408 - acc: 0.9875 - val_loss: 0.0444 - val_acc: 0.9853\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0362 - acc: 0.9890 - val_loss: 0.0352 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0323 - acc: 0.9900 - val_loss: 0.0397 - val_acc: 0.9866\n",
            "Accuracy: 0.9866 \n",
            " Error: 1.3400000000000034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QuvO2VxqlNwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Thank you for completing this lab!\n",
        "\n",
        "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!"
      ]
    },
    {
      "metadata": {
        "id": "PEaawM91lNwQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is part of a course on **edX** called *Deep Learning Fundamentals with Keras*. If you accessed this notebook outside the course, you can take this course online by clicking [here](http://cocl.us/DL0101EN_edX_Week4_LAB1)."
      ]
    },
    {
      "metadata": {
        "id": "nhizIjiolNwS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "Copyright &copy; 2018 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
      ]
    }
  ]
}